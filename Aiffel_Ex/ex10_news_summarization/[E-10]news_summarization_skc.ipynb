{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accessory-cocktail",
   "metadata": {},
   "source": [
    "### package import\n",
    "---\n",
    "필요한 패키지를 모두 import했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vertical-lesbian",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# GitHub의 어텐션 함수 다운로드\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer\n",
    "\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-stupid",
   "metadata": {},
   "source": [
    "### 데이터 가져오기\n",
    "---\n",
    "데이터셋을 받아 온 뒤, 데이터의 형태를 확인했습니다.\\\n",
    "text의 요약을 headlines로 판단하여 진행하도록 했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reported-editor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61415</th>\n",
       "      <td>Former CIA head slams Trump for attacking ex-i...</td>\n",
       "      <td>Former CIA chief John Brennan slammed US Presi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96186</th>\n",
       "      <td>Another African national attacked in Greater N...</td>\n",
       "      <td>According to reports, a female African student...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73725</th>\n",
       "      <td>Single ticket wins Ã¢ÂÂ¹4,860 crore lottery j...</td>\n",
       "      <td>A single ticket won the nearly $759 million (Ã...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31452</th>\n",
       "      <td>Shahid Kapoor confirms he will star in 'Arjun ...</td>\n",
       "      <td>Shahid Kapoor has confirmed he is starring in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15439</th>\n",
       "      <td>Venezuela 'a mess', needs to be 'cleaned up': ...</td>\n",
       "      <td>Amid continued criticism of the Venezuelan gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46572</th>\n",
       "      <td>Antimatter to be transported out of a lab for ...</td>\n",
       "      <td>In a first, antimatter made at the world's lar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42849</th>\n",
       "      <td>Good to let govt banks be free and owned by pu...</td>\n",
       "      <td>Infosys Chairman Nandan Nilekani has said it's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40644</th>\n",
       "      <td>Maharashtra state board introduces new syllabu...</td>\n",
       "      <td>The Maharashtra state education board introduc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93077</th>\n",
       "      <td>CBI files FIR against TMC leaders in Narada st...</td>\n",
       "      <td>The Central Bureau of Investigation on Monday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65453</th>\n",
       "      <td>Space radiation not a hurdle for a manned Mars...</td>\n",
       "      <td>As NASA is developing shielding material for s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "61415  Former CIA head slams Trump for attacking ex-i...   \n",
       "96186  Another African national attacked in Greater N...   \n",
       "73725  Single ticket wins Ã¢ÂÂ¹4,860 crore lottery j...   \n",
       "31452  Shahid Kapoor confirms he will star in 'Arjun ...   \n",
       "15439  Venezuela 'a mess', needs to be 'cleaned up': ...   \n",
       "46572  Antimatter to be transported out of a lab for ...   \n",
       "42849  Good to let govt banks be free and owned by pu...   \n",
       "40644  Maharashtra state board introduces new syllabu...   \n",
       "93077  CBI files FIR against TMC leaders in Narada st...   \n",
       "65453  Space radiation not a hurdle for a manned Mars...   \n",
       "\n",
       "                                                    text  \n",
       "61415  Former CIA chief John Brennan slammed US Presi...  \n",
       "96186  According to reports, a female African student...  \n",
       "73725  A single ticket won the nearly $759 million (Ã...  \n",
       "31452  Shahid Kapoor has confirmed he is starring in ...  \n",
       "15439  Amid continued criticism of the Venezuelan gov...  \n",
       "46572  In a first, antimatter made at the world's lar...  \n",
       "42849  Infosys Chairman Nandan Nilekani has said it's...  \n",
       "40644  The Maharashtra state education board introduc...  \n",
       "93077  The Central Bureau of Investigation on Monday ...  \n",
       "65453  As NASA is developing shielding material for s...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-cleveland",
   "metadata": {},
   "source": [
    "### 데이터 전처리1\n",
    "---\n",
    "중복을 배제한 수를 확인하고, 비어있는 값을 확인하여 headline과 text의 수를 같도록 만들었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pursuant-schedule",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headline 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headline 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fitted-return",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98262\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['headlines'], inplace = True)\n",
    "data.drop_duplicates(subset = ['text'], inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "imported-cleaners",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터프레임에 Null값이 있는지 확인\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-region",
   "metadata": {},
   "source": [
    "### 텍스트 정규화 와 불용어 제거\n",
    "---\n",
    "같은 의미의 단어를 통일시켜 연산량을 줄이고 불용어를 처리하여 성능을 높였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "second-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "banner-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "involved-greenhouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saurav kant an alumnus of upgrad and iiit pg program in machine learning and artificial intelligence was sr systems engineer at infosys with almost years of work experience the program and upgrad degree career support helped him transition to data scientist at tech mahindra with salary hike upgrad online power learning has powered lakh careers',\n",
       " 'kunal shah credit card bill payment platform cred gave users chance to win free food from swiggy for one year pranav kaushik delhi techie bagged this reward after spending cred coins users get one cred coin per rupee of bill paid which can be used to avail rewards from brands like ixigo bookmyshow ubereats cult fit and more',\n",
       " 'new zealand defeated india by wickets in the fourth odi at hamilton on thursday to win their first match of the five match odi series india lost an international match under rohit sharma captaincy after consecutive victories dating back to march the match witnessed india getting all out for their seventh lowest total in odi cricket history',\n",
       " 'with aegon life iterm insurance plan customers can enjoy tax benefits on your premiums paid and save up to on taxes the plan provides life cover up to the age of years also customers have options to insure against critical illnesses disability and accidental death benefit rider with life cover up to the age of years',\n",
       " 'speaking about the sexual harassment allegations against rajkumar hirani sonam kapoor said have known hirani for many years what if it is not true the metoo movement will get derailed in the metoo movement always believe woman but in this case we need to reserve our judgment she added hirani has been accused by an assistant who worked in sanju']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = []\n",
    "\n",
    "# 전체 text 데이터에 대한 전처리 \n",
    "for s in data['text']:\n",
    "    clean_text.append(preprocess_sentence(s, False))\n",
    "\n",
    "# 전처리 후 출력\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "norwegian-blade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['upgrad learner switches career ml al salary hike',\n",
       " 'delhi techie wins free food swiggy one year cred',\n",
       " 'new zealand end rohit sharma led india match winning streak',\n",
       " 'aegon life iterm insurance plan helps customers save tax',\n",
       " 'known hirani yrs metoo claims true sonam']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_summary = []\n",
    "\n",
    "# 전체 headline 데이터에 대한 전처리  \n",
    "for s in data['headlines']:\n",
    "    clean_summary.append(preprocess_sentence(s))\n",
    "\n",
    "clean_summary[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-membership",
   "metadata": {},
   "source": [
    "### 데이터 재확인\n",
    "---\n",
    "정제과정에서 사라진 데이터를 null로 치환하여 사라진 데이터를 확인했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "banned-premium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정제 과정에서 문장의 모든 단어가 사라지는 경우가 있을 수 있으므로 빈 값을 Null로 변환\n",
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-shadow",
   "metadata": {},
   "source": [
    "### 데이터 전처리 2\n",
    "---\n",
    "샘플의 최대길이를 결정하기 위해 길이와 분포를 출력 및 시각화했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vertical-sailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "헤드라인의 최소 길이 : 1\n",
      "헤드라인의 최대 길이 : 13\n",
      "헤드라인의 평균 길이 : 7.136787364393153\n",
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 69\n",
      "텍스트의 평균 길이 : 56.18195233152185\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "\n",
    "print('헤드라인의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('헤드라인의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('헤드라인의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-spending",
   "metadata": {},
   "source": [
    "### 최대길이 결정\n",
    "---\n",
    "분포를 참조하여 최대길이를 임의로 결정하고 그에 해당하는 샘플비율을 확인한 뒤, 기준에 맞게 샘플을 정리했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "funded-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대길이 임의 설정\n",
    "headlines_max_len = 11\n",
    "text_max_len = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "immune-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cellular-exemption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 11 이하인 샘플의 비율: 0.999745578148216\n",
      "전체 샘플 중 길이가 60 이하인 샘플의 비율: 0.9443528525778022\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(headlines_max_len, data['headlines'])\n",
    "below_threshold_len(text_max_len,  data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "moral-paraguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 92772\n"
     ]
    }
   ],
   "source": [
    "# 정해진 길이보다 길면 제외\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-belarus",
   "metadata": {},
   "source": [
    "### 시작 토큰과 종료 토큰을 추가\n",
    "---\n",
    "요약 데이터의 시작 토큰과 종료 토큰을 추가했습니다.\\\n",
    "그리고 이를 numpy 타입으로 저장했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "judicial-chorus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches career ml al salary hike</td>\n",
       "      <td>saurav kant an alumnus of upgrad and iiit pg p...</td>\n",
       "      <td>sostoken upgrad learner switches career ml al ...</td>\n",
       "      <td>upgrad learner switches career ml al salary hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food swiggy one year cred</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food swiggy on...</td>\n",
       "      <td>delhi techie wins free food swiggy one year cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india by wickets in the f...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>with aegon life iterm insurance plan customers...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>known hirani yrs metoo claims true sonam</td>\n",
       "      <td>speaking about the sexual harassment allegatio...</td>\n",
       "      <td>sostoken known hirani yrs metoo claims true sonam</td>\n",
       "      <td>known hirani yrs metoo claims true sonam eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0   upgrad learner switches career ml al salary hike   \n",
       "1   delhi techie wins free food swiggy one year cred   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "4           known hirani yrs metoo claims true sonam   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant an alumnus of upgrad and iiit pg p...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india by wickets in the f...   \n",
       "3  with aegon life iterm insurance plan customers...   \n",
       "4  speaking about the sexual harassment allegatio...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches career ml al ...   \n",
       "1  sostoken delhi techie wins free food swiggy on...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "4  sostoken known hirani yrs metoo claims true sonam   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches career ml al salary hi...  \n",
       "1  delhi techie wins free food swiggy one year cr...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "4  known hirani yrs metoo claims true sonam eostoken  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "outside-front",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = np.array(data['headlines']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-brush",
   "metadata": {},
   "source": [
    "### 훈련 자료와 시험 자료 나누기\n",
    "---\n",
    "indice를 이용하여 순서를 섞은 뒤, 이를 8:2로 나눴습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "excess-zealand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25989 64544 68982 ... 15379 15499 59522]\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 정수 시퀀스를 이용하여 나눔\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "final-springfield",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 18554\n"
     ]
    }
   ],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "heard-simpson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 74218\n",
      "훈련 레이블의 개수 : 74218\n",
      "테스트 데이터의 개수 : 18554\n",
      "테스트 레이블의 개수 : 18554\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-banner",
   "metadata": {},
   "source": [
    "### 데이터 전처리 3\n",
    "---\n",
    "keras를 이용하여 단어사전을 만들고 이를 토큰화하는 작업을 했습니다.\\\n",
    "등장빈도가 5회 미만인 단어는 학습에서 제외했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cellular-volleyball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 29400\n",
      "등장 빈도가 4번 이하인 희귀 단어의 수: 18276\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11124\n",
      "단어 집합에서 희귀 단어의 비율: 62.16326530612245\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.922040114179852\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성\n",
    "\n",
    "threshold = 5 # 등장 빈도수\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "billion-cheese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19, 8, 71, 94, 60, 45], [1, 883, 232, 4542, 47, 3840, 191, 213], [12, 1770, 9103, 1230, 370, 16, 13]]\n",
      "[[431, 797, 10174, 1396, 116, 72], [28, 1936, 715, 561, 2154, 2568], [164, 359, 700, 1947, 4028, 3695]]\n"
     ]
    }
   ],
   "source": [
    "src_vocab = 11000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) # 단어 집합의 크기를 11,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성.\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "#잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])\n",
    "print(encoder_input_test[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "annoying-denmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 29401\n",
      "등장 빈도가 4번 이하인 희귀 단어의 수: 18276\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11125\n",
      "단어 집합에서 희귀 단어의 비율: 62.16115098125914\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.193399291786581\n"
     ]
    }
   ],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "\n",
    "threshold = 5\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "accurate-certification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 21, 10, 73, 96, 62, 47], [1, 3, 885, 234, 4544, 49, 3842, 193, 215], [1, 14, 1772, 9105, 1232, 372, 18, 15], [1, 291, 745, 1686, 4880, 3047, 2907], [1, 37, 18, 239, 5080, 181, 227, 18]]\n",
      "target\n",
      "decoder  [[21, 10, 73, 96, 62, 47, 2], [3, 885, 234, 4544, 49, 3842, 193, 215, 2], [14, 1772, 9105, 1232, 372, 18, 15, 2], [291, 745, 1686, 4880, 3047, 2907, 2], [37, 18, 239, 5080, 181, 227, 18, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 11000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "loaded-yacht",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1\n",
      "삭제할 테스트 데이터의 개수 : 2\n",
      "훈련 데이터의 개수 : 74217\n",
      "훈련 레이블의 개수 : 74217\n",
      "테스트 데이터의 개수 : 18552\n",
      "테스트 레이블의 개수 : 18552\n"
     ]
    }
   ],
   "source": [
    "# 빈도수가 낮은 단어들로만 구성되었던 문장들을 제거\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-benjamin",
   "metadata": {},
   "source": [
    "### 패딩 추가\n",
    "---\n",
    "모델에 이용하기위해 패딩을 추가하여 길이를 텐서의 형태를 맞춰줬습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "breathing-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-daniel",
   "metadata": {},
   "source": [
    "### 모델 설계\n",
    "---\n",
    "4개의 층과 128개의 임베딩 벡터, 256개의 hidden state로 구성되는 인코더를 만들었습니다.\\\n",
    "디코더에는 단어를 선택하기 위해 dense에 tav_vocab을 이용하고 활성화 함수로 softmax를 이용했습니다.\\\n",
    "또한 성능향상을 위해 어텐션 메커니즘을 이용했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "demonstrated-moment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 60, 128)      1408000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 60, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 60, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 60, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1408000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 60, 256), (N 525312      lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 11000)  2827000     lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,007,416\n",
      "Trainable params: 8,007,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128 # 임베딩벡터의 차원 수\n",
    "hidden_size = 256 # LSTM에서 얼만큼의 수용력(capacity)를 가질지를 정하는 파라미터로 층 1개의 용량의 크기를 나타냄\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 4개로 구성하여 모델의 용량을 늘림\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output3, state_h3, state_c3= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# 인코더의 LSTM 4\n",
    "encoder_lstm4 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm4(encoder_output3)\n",
    "\n",
    "\n",
    "# 디코더 설계\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-hanging",
   "metadata": {},
   "source": [
    "### 어텐션 메커니즘\n",
    "---\n",
    "노드와 마찬가지로 깃헙의 어텐션 메커니즘을 이용하여 모델의 출력층을 수정했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "reliable-prophet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 60, 128)      1408000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 60, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 60, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 60, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1408000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 60, 256), (N 525312      lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_3[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_4[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 11000)  5643000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,954,744\n",
      "Trainable params: 10,954,744\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-synthetic",
   "metadata": {},
   "source": [
    "### 모델 훈련\n",
    "---\n",
    "node와 같이 earlystopping을 적용해서 조기종료가 이루어지도록 하고 학습을 진행했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "nuclear-regard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "290/290 [==============================] - 361s 1s/step - loss: 5.5853 - val_loss: 4.8746\n",
      "Epoch 2/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 4.8654 - val_loss: 4.5516\n",
      "Epoch 3/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 4.5352 - val_loss: 4.1786\n",
      "Epoch 4/50\n",
      "290/290 [==============================] - 345s 1s/step - loss: 4.1579 - val_loss: 3.7789\n",
      "Epoch 5/50\n",
      "290/290 [==============================] - 345s 1s/step - loss: 3.7759 - val_loss: 3.4505\n",
      "Epoch 6/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 3.3915 - val_loss: 2.8698\n",
      "Epoch 7/50\n",
      "290/290 [==============================] - 345s 1s/step - loss: 2.9358 - val_loss: 2.3701\n",
      "Epoch 8/50\n",
      "290/290 [==============================] - 346s 1s/step - loss: 2.5152 - val_loss: 2.0177\n",
      "Epoch 9/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 2.1891 - val_loss: 1.7032\n",
      "Epoch 10/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 1.9103 - val_loss: 1.5330\n",
      "Epoch 11/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 1.6798 - val_loss: 1.3378\n",
      "Epoch 12/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 1.5162 - val_loss: 1.1896\n",
      "Epoch 13/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 1.3493 - val_loss: 1.1018\n",
      "Epoch 14/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 1.2248 - val_loss: 1.0021\n",
      "Epoch 15/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 1.1088 - val_loss: 0.9371\n",
      "Epoch 16/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 1.0139 - val_loss: 0.8690\n",
      "Epoch 17/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 0.9408 - val_loss: 0.8178\n",
      "Epoch 18/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 0.8716 - val_loss: 0.7688\n",
      "Epoch 19/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 0.7985 - val_loss: 0.7384\n",
      "Epoch 20/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 0.7503 - val_loss: 0.6922\n",
      "Epoch 21/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 0.7012 - val_loss: 0.6623\n",
      "Epoch 22/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 0.6606 - val_loss: 0.6401\n",
      "Epoch 23/50\n",
      "290/290 [==============================] - 343s 1s/step - loss: 0.6255 - val_loss: 0.6133\n",
      "Epoch 24/50\n",
      "290/290 [==============================] - 346s 1s/step - loss: 0.5891 - val_loss: 0.5900\n",
      "Epoch 25/50\n",
      "290/290 [==============================] - 350s 1s/step - loss: 0.5539 - val_loss: 0.5611\n",
      "Epoch 26/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 0.5222 - val_loss: 0.5440\n",
      "Epoch 27/50\n",
      "290/290 [==============================] - 347s 1s/step - loss: 0.4933 - val_loss: 0.5350\n",
      "Epoch 28/50\n",
      "290/290 [==============================] - 348s 1s/step - loss: 0.4698 - val_loss: 0.5143\n",
      "Epoch 29/50\n",
      "290/290 [==============================] - 349s 1s/step - loss: 0.4473 - val_loss: 0.4993\n",
      "Epoch 30/50\n",
      "290/290 [==============================] - 352s 1s/step - loss: 0.4262 - val_loss: 0.4864\n",
      "Epoch 31/50\n",
      "290/290 [==============================] - 352s 1s/step - loss: 0.4052 - val_loss: 0.4649\n",
      "Epoch 32/50\n",
      "290/290 [==============================] - 345s 1s/step - loss: 0.3839 - val_loss: 0.4637\n",
      "Epoch 33/50\n",
      "290/290 [==============================] - 350s 1s/step - loss: 0.3727 - val_loss: 0.4563\n",
      "Epoch 34/50\n",
      "290/290 [==============================] - 352s 1s/step - loss: 0.3594 - val_loss: 0.4494\n",
      "Epoch 35/50\n",
      "290/290 [==============================] - 349s 1s/step - loss: 0.3504 - val_loss: 0.4379\n",
      "Epoch 36/50\n",
      "290/290 [==============================] - 351s 1s/step - loss: 0.3340 - val_loss: 0.4350\n",
      "Epoch 37/50\n",
      "290/290 [==============================] - 354s 1s/step - loss: 0.3257 - val_loss: 0.4256\n",
      "Epoch 38/50\n",
      "290/290 [==============================] - 348s 1s/step - loss: 0.3125 - val_loss: 0.4257\n",
      "Epoch 39/50\n",
      "290/290 [==============================] - 349s 1s/step - loss: 0.3046 - val_loss: 0.4118\n",
      "Epoch 40/50\n",
      "290/290 [==============================] - 352s 1s/step - loss: 0.2955 - val_loss: 0.4057\n",
      "Epoch 41/50\n",
      "290/290 [==============================] - 359s 1s/step - loss: 0.2869 - val_loss: 0.3968\n",
      "Epoch 42/50\n",
      "290/290 [==============================] - 349s 1s/step - loss: 0.2793 - val_loss: 0.3976\n",
      "Epoch 43/50\n",
      "290/290 [==============================] - 351s 1s/step - loss: 0.2707 - val_loss: 0.3898\n",
      "Epoch 44/50\n",
      "290/290 [==============================] - 353s 1s/step - loss: 0.2593 - val_loss: 0.3795\n",
      "Epoch 45/50\n",
      "290/290 [==============================] - 351s 1s/step - loss: 0.2531 - val_loss: 0.3776\n",
      "Epoch 46/50\n",
      "290/290 [==============================] - 346s 1s/step - loss: 0.2461 - val_loss: 0.3819\n",
      "Epoch 47/50\n",
      "290/290 [==============================] - 345s 1s/step - loss: 0.2362 - val_loss: 0.3696\n",
      "Epoch 48/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 0.2337 - val_loss: 0.3581\n",
      "Epoch 49/50\n",
      "290/290 [==============================] - 344s 1s/step - loss: 0.2268 - val_loss: 0.3554\n",
      "Epoch 50/50\n",
      "290/290 [==============================] - 347s 1s/step - loss: 0.2212 - val_loss: 0.3518\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-uruguay",
   "metadata": {},
   "source": [
    "### 학습결과 확인\n",
    "---\n",
    "50epoch안에 종료 될 것이라는 기대와 달리 훈련이 계속되었습니다.\\\n",
    "엔진의 성능이 올라가므로, 훈련을 더 했어야 하나 싶었지만,\\\n",
    "validation 결과가 훈련 결과처럼 낮아지는 지점은 넘었기때문에, 적절한 훈련양이었을 수도 있겠다 싶습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "verbal-wallpaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resident-ambassador",
   "metadata": {},
   "source": [
    "### 인퍼런스 모델\n",
    "---\n",
    "정수 인덱스를 다시 실제 데이터로 복원하기 위한 사전을 형성하고,\\\n",
    "인퍼런스를 위한 별도의 모델을 설계했습니다.\\\n",
    "정답이 없고 문장을 만들어야 하기 때문입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "spanish-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "\n",
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "indonesian-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (text_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-floating",
   "metadata": {},
   "source": [
    "### 모델 확인\n",
    "---\n",
    "테스트 데이터에서 약 20개정도만 headline과 예측된 요약을 비교했습니다.\\\n",
    "여기서 현재까지 진행한 '추상적 요약'방식외에 '추출적 요약 방식도 추가하여 비교 할 계획이었지만,\\\n",
    "추출적 요약 방식을 위한 summa가 어떠한 단어도 출력하지 않기에 추상적 요약만 진행했습니다.\\\n",
    "\n",
    "추상적 요약의 진행 결과는 실제요약과 매우 유사한 출력을 만들어내는 것을 확인 할 수 있었습니다.\\\n",
    "중간에 일치하지 않는 지점이 없었다면 예측이 아니라 복사라고 생각했을 정도기에,\\\n",
    "학습이 잘 됬다고 생각합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "actual-webcam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : like film watch madras hc row \n",
      "실제 요약 : like film watch madras hc row \n",
      "예측 요약 :  like film watch madras hc row\n",
      "\n",
      "\n",
      "원문 : trump admin challenges travel ban ruling supreme court \n",
      "실제 요약 : trump admin challenges travel ban ruling supreme court \n",
      "예측 요약 :  trump admin challenges travel ban ruling supreme court\n",
      "\n",
      "\n",
      "원문 : taj mahal ticket price may increase nd time yrs \n",
      "실제 요약 : taj mahal ticket price may increase nd time yrs \n",
      "예측 요약 :  taj mahal ticket price may increase nd time yrs\n",
      "\n",
      "\n",
      "원문 : patents self driving cars take criminals jail \n",
      "실제 요약 : patents self driving cars take criminals jail \n",
      "예측 요약 :  ousted self driving cars take criminals jail\n",
      "\n",
      "\n",
      "원문 : free nation rape mentality pm modi \n",
      "실제 요약 : free nation rape mentality pm modi \n",
      "예측 요약 :  free nation rape spared pm modi\n",
      "\n",
      "\n",
      "원문 : islamic state releases video threatening pope \n",
      "실제 요약 : islamic state releases video threatening pope \n",
      "예측 요약 :  islamic state releases video threatening pope\n",
      "\n",
      "\n",
      "원문 : russian train introduces special stop one \n",
      "실제 요약 : russian train introduces special stop one \n",
      "예측 요약 :  russian train introduces special stop one\n",
      "\n",
      "\n",
      "원문 : cape town pushes day run water july \n",
      "실제 요약 : cape town pushes day run water july \n",
      "예측 요약 :  cape town pushes day run water july\n",
      "\n",
      "\n",
      "원문 : sitharaman drama ran away questions rahul \n",
      "실제 요약 : sitharaman drama ran away questions rahul \n",
      "예측 요약 :  sitharaman lied ran away questions rahul\n",
      "\n",
      "\n",
      "원문 : technologies like ai pose security challenges home minister \n",
      "실제 요약 : technologies like ai pose security challenges home minister \n",
      "예측 요약 :  din like ai pose security challenges home minister\n",
      "\n",
      "\n",
      "원문 : bigg boss contestant booked fake iphone ad instagram \n",
      "실제 요약 : bigg boss contestant booked fake iphone ad instagram \n",
      "예측 요약 :  bigg boss contestant booked fake iphone ad instagram\n",
      "\n",
      "\n",
      "원문 : kxip appoint mike head coach ipl \n",
      "실제 요약 : kxip appoint mike head coach ipl \n",
      "예측 요약 :  kxip appoint cop head coach ipl\n",
      "\n",
      "\n",
      "원문 : kylie jenner shares pictures barbie themed photoshoot \n",
      "실제 요약 : kylie jenner shares pictures barbie themed photoshoot \n",
      "예측 요약 :  kylie jenner shares pictures please themed spain\n",
      "\n",
      "\n",
      "원문 : investor demanded uber ceo resignation praises \n",
      "실제 요약 : investor demanded uber ceo resignation praises \n",
      "예측 요약 :  investor vandalise uber ceo resignation praises\n",
      "\n",
      "\n",
      "원문 : whatsapp rolls change number feature beta \n",
      "실제 요약 : whatsapp rolls change number feature beta \n",
      "예측 요약 :  whatsapp rolls change number feature beta\n",
      "\n",
      "\n",
      "원문 : zakir naik deported india malaysian pm \n",
      "실제 요약 : zakir naik deported india malaysian pm \n",
      "예측 요약 :  rickshaw ideology deported india malaysian pm\n",
      "\n",
      "\n",
      "원문 : tn man undergoes surgery brain tissue found ear \n",
      "실제 요약 : tn man undergoes surgery brain tissue found ear \n",
      "예측 요약 :  tn man undergoes surgery brain million found ear\n",
      "\n",
      "\n",
      "원문 : delhi man cheats last rites \n",
      "실제 요약 : delhi man cheats last rites \n",
      "예측 요약 :  delhi man cheats last rites\n",
      "\n",
      "\n",
      "원문 : trump discusses jong un duterte leaked call \n",
      "실제 요약 : trump discusses jong un duterte leaked call \n",
      "예측 요약 :  trump likens jong un duterte leaked call\n",
      "\n",
      "\n",
      "원문 : ready court settlement babri case \n",
      "실제 요약 : ready court settlement babri case \n",
      "예측 요약 :  ready court summons babri case\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 70):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "#     print(\"추출 요약 :\", summarize(data['text'][i], words=headlines_max_len))\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-beauty",
   "metadata": {},
   "source": [
    "### summa 를 활용하기 위한 시도\n",
    "---\n",
    "노드에서 제공된 text를 이용하여 요약한 결과 매우 잘 작동하는 것을 확인했습니다.\\\n",
    "뉴스기사 데이터를 이용한 경우에는 아무 것도 출력이 되지 않는데,\\\n",
    "이는 영어 문장 구조의 형식을 데이터가 지켜주지 않기 때문이라고 생각했습니다.\\\n",
    "따라서 문장의 첫 문자를 대문자로 전환하고 마지막에 마침표를 추가하는 시도를 해보았습니다만,\\\n",
    "여전히 같은 결과를 얻을 수 있을 뿐이었습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "proud-money",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize\n",
    "\n",
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text\n",
    "\n",
    "print(text[:1500])\n",
    "print(type(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "specialized-model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, words=headlines_max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "involved-livestock",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 15",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-4ff03a44e6ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# textf = textf[['headlines','text']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# textf = pd.DataFrame(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtextc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# print(textf[:100])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 15"
     ]
    }
   ],
   "source": [
    "from summa.summarizer import summarize\n",
    "\n",
    "# textf = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1', dtype={'headlines':'str', 'text':'str'})\n",
    "# textf = textf[['headlines','text']]\n",
    "# textf = pd.DataFrame(data)\n",
    "textc = data['text'][15]\n",
    "# print(textf[:100])\n",
    "print(textc[:50])\n",
    "print('Summary:')\n",
    "\n",
    "print(summarize(textc, ratio=0.005))\n",
    "\n",
    "print(summarize(clean_text[9], words = 11), len(textc))\n",
    "#print(summarize(data2['headlines']))\n",
    "# print(summarize(clean_text[0], words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "moved-property",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clean_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "extreme-mileage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saurav kant an alumnus of upgrad and iiit pg program in machine learning and artificial intelligence was sr systems engineer at infosys with almost years of work experience the program and upgrad degree career support helped him transition to data scientist at tech mahindra with salary hike upgrad online power learning has powered lakh careers'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "indie-laptop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'upgrad learner switches career ml al salary hike'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "pursuant-peninsula",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Saurav kant an alumnus of upgrad and iiit pg program in machine learning and artificial intelligence was sr systems engineer at infosys with almost years of work experience the program and upgrad degree career support helped him transition to data scientist at tech mahindra with salary hike upgrad online power learning has powered lakh careers.\n",
      "추출 요약 : \n",
      "추출 요약 : \n",
      "추출 요약 : \n"
     ]
    }
   ],
   "source": [
    "\n",
    "text3=data['text'][0] + '.'\n",
    "text3=text3.capitalize()\n",
    "print(type(text3))\n",
    "print(text3)\n",
    "print(\"추출 요약 :\", summarize(text3, words=headlines_max_len))\n",
    "print(\"추출 요약 :\", summarize(text3, language='english'))\n",
    "print(\"추출 요약 :\", summarize(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-longer",
   "metadata": {},
   "source": [
    "### 회고\n",
    "---\n",
    "추출적 요약 결과를 얻을 수 없어서 제대로 완수하지 못 한 노드가 된 것 같습니다.\\\n",
    "완성여부와 별개로 갖게 된 의문 중에 하나는, 예측을 위해 별도의 모델을 형성하는데,\\\n",
    "이 경우 데이터의 훈련이 예측에 어떤 도움을 줄 수 있는지 모르겠습니다.\\\n",
    "특히 코드상으로 model이 예측과정에서 전혀 쓰이지 않는 것을 확인했습니다.\\\n",
    "훈련된 모델을 별도로 둔다면, 훈련과정 역시 무의미한 것이 아니었을까요?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-details",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
